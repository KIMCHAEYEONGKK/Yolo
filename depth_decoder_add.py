import torch
import torch.nn as nn
import torch.nn.functional as F
from collections import OrderedDict
from timm.layers import trunc_normal_

class ConvBlock(nn.Module): #ì—…ìƒ˜í”Œí›„ feature ì •ë¦¬ í• ë•Œ ì‚¬ìš©
    """ê¸°ë³¸ Convolution Block: Conv2d + ELU"""
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1), 
            #3x3 kernel, stride=1, padding=1(í•´ìƒë„ ìœ ì§€)
            nn.ELU(inplace=True)
            #activationí•¨ìˆ˜ (rely ë³´ë‹¤ ë¶€ë“œëŸ½ê³  gradient vanishing ì ìŒ)
        )

    def forward(self, x): #ìž…ë ¥ì„ conv+activationì„ ê±°ì³ ì¶œë ¥
        return self.conv(x)

class Conv3x3(nn.Module): #ìµœì¢… depthmapë½‘ì„ ë•Œ ì‚¬ìš©
    """3x3 Convolution for output depth/disparity"""
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)

    def forward(self, x):
        return self.conv(x)

def upsample(x, mode="bilinear"): #decoderì—ì„œ resolutionì„ í‚¤ìš°ê¸° ìœ„í•´ì„œ ì‚¬ìš©
    """Bilinear upsampling by a factor of 2"""
    return F.interpolate(x, scale_factor=2, mode=mode, align_corners=True)
#F.interpolateëŠ” ìž…ë ¥ feautureë¥¼ í•´ìƒë„ 2ë°°ë¡œ ì—…ìƒ˜í”Œë§
#mode='bilinear'ì€ ë¶€ë“œëŸ¬ìš´ interpolationë°©ì‹
#align_corners=TrueëŠ” cornerìœ„ì¹˜ ë§žì¶”ê¸°(deeplab, monodepthê³„ì—´ì— ì£¼ë¡œ ì‚¬ìš©)

class DepthDecoder(nn.Module):
    def __init__(self, num_ch_enc, scales=range(4), num_output_channels=1, use_skips=True):
        
        super().__init__()

        self.num_output_channels = num_output_channels
        self.use_skips = use_skips
        self.upsample_mode = 'bilinear'
        self.scales = scales

        self.num_ch_enc = num_ch_enc
        self.num_ch_dec = (self.num_ch_enc / 2).astype('int')  # Decoder ì±„ë„ ìˆ˜: Encoderë³´ë‹¤ ì ˆë°˜

        # ðŸ”¹ Decoder layers
        self.convs = OrderedDict()

        for i in range(2, -1, -1):  # 2 â†’ 1 â†’ 0
            # upconv_0: Upsampleì„ ìœ„í•œ Conv
            num_ch_in = self.num_ch_enc[-1] if i == 2 else self.num_ch_dec[i + 1]
            num_ch_out = self.num_ch_dec[i]
            self.convs[("upconv", i, 0)] = ConvBlock(num_ch_in, num_ch_out)

            # upconv_1: Skip ì—°ê²° í›„ feature ì •ë¦¬
            num_ch_in = self.num_ch_dec[i]
            if self.use_skips and i > 0:
                num_ch_in += self.num_ch_enc[i - 1]  # skip ì—°ê²° ì¶”ê°€
            num_ch_out = self.num_ch_dec[i]
            self.convs[("upconv", i, 1)] = ConvBlock(num_ch_in, num_ch_out)

        # ðŸ”¹ Disparity prediction layers
        for s in self.scales:
            self.convs[("dispconv", s)] = Conv3x3(self.num_ch_dec[s], self.num_output_channels)

        # ModuleListë¡œ ë³€í™˜
        self.decoder = nn.ModuleList(list(self.convs.values()))
        self.sigmoid = nn.Sigmoid()

        self.apply(self._init_weights)

    def _init_weights(self, m):
        if isinstance(m, (nn.Conv2d, nn.Linear)):
            trunc_normal_(m.weight, std=0.02)
            if m.bias is not None:
                nn.init.constant_(m.bias, 0)

    def forward(self, input_features):
        outputs = {}
        x = input_features[-1]  # ê°€ìž¥ ê¹Šì€ featureë¶€í„° ì‹œìž‘

        for i in range(2, -1, -1):
            # 1. Upsample Conv
            x = self.convs[("upconv", i, 0)](x)
            x = [upsample(x, mode=self.upsample_mode)]

            # 2. Skip ì—°ê²°
            if self.use_skips and i > 0:
                x += [input_features[i - 1]]
            x = torch.cat(x, dim=1)  # Channel ë°©í–¥ìœ¼ë¡œ concat

            # 3. Skip ì—°ê²° í›„ Conv
            x = self.convs[("upconv", i, 1)](x)

            # 4. Disparity ì˜ˆì¸¡
            if i in self.scales:
                disp = upsample(self.convs[("dispconv", i)](x), mode=self.upsample_mode)
                outputs[("disp", i)] = self.sigmoid(disp)

        return outputs
